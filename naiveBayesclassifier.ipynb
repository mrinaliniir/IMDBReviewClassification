{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Sentiment Prediction using Naive Bayes Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemented Naive Bayes classfier to predict the sentiment of movie review. Naive Bayes Classifier assumes conditional independence among features. Compared the results obt with the results of Multinomial Naive Bayes Classier provided by sklearn library and achieved similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  [one, of, the, other, reviewers, has, mentione...          1\n",
      "4  [petter, matteis, love, in, the, time, of, mon...          1\n",
      "9  [if, you, like, original, gut, wrenching, laug...          1\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"C:/Users/irmri/OneDrive/Desktop/IMDB Dataset.csv\") # read csv\n",
    "\n",
    "# Preprocessing the text \n",
    "df['sentiment'] = df.sentiment.map({'negative': 0, 'positive': 1})  \n",
    "df['review'] = df.review.map(lambda x: x.lower()) \n",
    "df['review'] = df['review'].str.replace('[^\\w\\s]','')\n",
    "df['review'] = df['review'].apply(nltk.word_tokenize)\n",
    "train = df.sample(frac=0.7, random_state=200)\n",
    "test = df.drop(train.index)\n",
    "print(test)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stops(row):\n",
    "\tmy_list = row\n",
    "\tmeaningful_words =' '.join([w for w in my_list if not w in stop_words])\n",
    "\treturn (meaningful_words)\n",
    "\n",
    "train['review'] = train['review'].apply(remove_stops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of the word\n",
    "vect = CountVectorizer()\n",
    "dtm_train = vect.fit_transform(train['review']) # create a document term matrix\n",
    "freqcols = np.array(dtm_train.sum(axis = 0)).flatten()\n",
    "freqrows = np.array(dtm_train.sum(axis = 1)).flatten()\n",
    "total_words = np.sum(freqrows)\n",
    "prob_word = freqcols/total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sepearte the postive reviews from the negative reviews\n",
    "vect1 = CountVectorizer()\n",
    "vect2 = CountVectorizer()\n",
    "pos_reviews = train.loc[train['sentiment'] == 1,'review']\n",
    "neg_reviews = train.loc[train['sentiment'] == 0,'review']\n",
    "dtm_train_pos = vect1.fit_transform(pos_reviews)\n",
    "dtm_train_neg = vect2.fit_transform(neg_reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqcols_pos = np.array(dtm_train_pos.sum(axis=0)).flatten()\n",
    "freqrows_pos = np.array(dtm_train_pos.sum(axis=1)).flatten()\n",
    "freqcols_neg = np.array(dtm_train_neg.sum(axis=0)).flatten()\n",
    "freqrows_neg = np.array(dtm_train_neg.sum(axis=1)).flatten()\n",
    "\n",
    "total_words_pos = np.sum(freqrows_pos)\n",
    "total_words_neg = np.sum(freqrows_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the probability of positive and negative sentiments\n",
    "prob_sentiment_pos = pos_reviews.size / len(train)\n",
    "prob_sentiment_neg = neg_reviews.size / len(train)\n",
    "\n",
    "prob_word_pos = freqcols_pos/ total_words_pos\n",
    "feature_names_pos = np.asarray(vect1.get_feature_names())\n",
    "prob_word_neg = freqcols_neg/total_words_neg\n",
    "feature_names_neg = np.asarray(vect2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df= pd.DataFrame()\n",
    "neg_df = pd.DataFrame()\n",
    "pos_df['word']= feature_names_pos\n",
    "pos_df['probability'] = prob_word_pos\n",
    "neg_df['word'] = feature_names_neg\n",
    "neg_df['probability'] = prob_word_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49866666666666665\n"
     ]
    }
   ],
   "source": [
    "def probSentiment_sentence(sentence):\n",
    "    alpha = 0.0000001\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    meaningful_words = [w for w in sentence if not w in stop_words]\n",
    "    pos_prob = np.log(prob_sentiment_pos)\n",
    "    neg_prob = np.log(prob_sentiment_neg)\n",
    "\n",
    "    for i in range(len(meaningful_words)):\n",
    "        pos_word_prob = pos_df.loc[pos_df['word']== meaningful_words[i],\"probability\"].tolist()\n",
    "        neg_word_prob = neg_df.loc[neg_df['word']== meaningful_words[i],\"probability\"].tolist()\n",
    "        if(len(pos_word_prob) == 0):\n",
    "            pos_prob += alpha\n",
    "        else:\n",
    "            pos_prob += np.log(pos_word_prob[0])\n",
    "        if(len(neg_word_prob) == 0):\n",
    "            pos_prob += alpha\n",
    "        else:\n",
    "            neg_prob += np.log(neg_word_prob[0])\n",
    "    \n",
    "    if(pos_prob > neg_prob):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "\n",
    "result = []\n",
    "for index, row in test.iterrows():\n",
    "    result.append(probSentiment_sentence(row['review']))\n",
    "\n",
    "def classification_rate(predicted, actual):\n",
    "    count = 0\n",
    "    for index in range(len(predicted)):\n",
    "        if predicted[index] == actual[index]:\n",
    "            count +=1\n",
    "    return count/len(predicted)\n",
    "\n",
    "print(classification_rate(result, test['sentiment'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results of Naive Bayes Classifier from sklearn library \n",
    "df = pd.read_csv(\"C:/Users/irmri/OneDrive/Desktop/IMDB Dataset.csv\") # read csv\n",
    "df = df.head(10)\n",
    "df['sentiment'] = df.sentiment.map({'negative': 0, 'positive': 1})  \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'],test_size=0.2)\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_dtm, y_train)\n",
    "y_pred_class = mnb.predict(X_test_dtm)\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
